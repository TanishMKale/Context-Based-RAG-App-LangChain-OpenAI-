{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77569ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b02ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"GEN-AIAPPWITHOPENAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cf0a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TANISH KALE\\Desktop\\langchain_embedding_openai_oilama etc\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "#load the data of website\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "    web_path = \"https://docs.langchain.com/langsmith/generative-ui-react\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6340e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='How to implement generative user interfaces with LangGraph - Docs by LangChainSkip to main contentDocs by LangChain home pageLangSmithSearch...⌘KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationTutorialsHow to implement generative user interfaces with LangGraphGet startedObservabilityEvaluationPrompt engineeringDeploymentPlatform setupReferenceOverviewTest locallyApp developmentCloud quickstartLocal development & testingConfigure app for deploymentApplication structureSetupDeployment componentsRebuild graph at runtimeInteract with a deployment using RemoteGraphAdd semantic search to your agent deploymentAdd TTLs to your applicationConfigure Agent Server for scaleImplement a CI/CD pipelineDeployment guidesCloudWith control planeStandalone serversTroubleshootingApp developmentData modelsCore capabilitiesTutorialsDeploy other frameworks (e.g., Strands, CrewAI)Implement generative user interfaces with LangGraphStudioOverviewQuickstartRuns, assistants, threadsTraces, datasets, promptsTroubleshootingAuth & access controlOverviewAdd custom authenticationSet up custom authenticationMake conversations privateConnect an authentication providerDocument API authentication in OpenAPISet up Agent Auth (Beta)Server customizationAdd custom lifespan eventsAdd custom middlewareAdd custom routesEncryption at-restConfigurable headersLogging HeadersOn this pageTutorial1. Define and configure UI components2. Send the UI components in your graph3. Handle UI elements in your React applicationHow-to guidesProvide custom components on the client sideShow loading UI when components are loadingCustomise the namespace of UI components.Access and interact with the thread state from the UI componentPass additional context to the client componentsStreaming UI messages from the serverRemove UI messages from stateLearn moreApp developmentTutorialsHow to implement generative user interfaces with LangGraphCopy pageCopy pagePrerequisites\\nLangSmith\\nAgent Server\\nuseStream() React Hook\\n\\nGenerative user interfaces (Generative UI) allows agents to go beyond text and generate rich user interfaces. This enables creating more interactive and context-aware applications where the UI adapts based on the conversation flow and AI responses.\\n\\nLangSmith supports colocating your React components with your graph code. This allows you to focus on building specific UI components for your graph while easily plugging into existing chat interfaces such as Agent Chat and loading the code only when actually needed.\\n\\u200bTutorial\\n\\u200b1. Define and configure UI components\\nFirst, create your first UI component. For each component you need to provide an unique identifier that will be used to reference the component in your graph code.\\nsrc/agent/ui.tsxCopyconst WeatherComponent = (props: { city: string }) => {\\n  return <div>Weather for {props.city}</div>;\\n};\\n\\nexport default {\\n  weather: WeatherComponent,\\n};\\n\\nNext, define your UI components in your langgraph.json configuration:\\nCopy{\\n  \"node_version\": \"20\",\\n  \"graphs\": {\\n    \"agent\": \"./src/agent/index.ts:graph\"\\n  },\\n  \"ui\": {\\n    \"agent\": \"./src/agent/ui.tsx\"\\n  }\\n}\\n\\nThe ui section points to the UI components that will be used by graphs. By default, we recommend using the same key as the graph name, but you can split out the components however you like, see Customise the namespace of UI components for more details.\\nLangSmith will automatically bundle your UI components code and styles and serve them as external assets that can be loaded by the LoadExternalComponent component. Some dependencies such as react and react-dom will be automatically excluded from the bundle.\\nCSS and Tailwind 4.x is also supported out of the box, so you can freely use Tailwind classes as well as shadcn/ui in your UI components.\\n src/agent/ui.tsx src/agent/styles.cssCopyimport \"./styles.css\";\\n\\nconst WeatherComponent = (props: { city: string }) => {\\n  return <div className=\"bg-red-500\">Weather for {props.city}</div>;\\n};\\n\\nexport default {\\n  weather: WeatherComponent,\\n};\\nCopy@import \"tailwindcss\";\\n\\n\\u200b2. Send the UI components in your graph\\n Python JSsrc/agent.pyCopyimport uuid\\nfrom typing import Annotated, Sequence, TypedDict\\n\\nfrom langchain.messages import AIMessage\\nfrom langchain_core.messages import BaseMessage\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.graph.ui import AnyUIMessage, ui_message_reducer, push_ui_message\\n\\n\\nclass AgentState(TypedDict):  # noqa: D101\\n    messages: Annotated[Sequence[BaseMessage], add_messages]\\n    ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]\\n\\n\\nasync def weather(state: AgentState):\\n    class WeatherOutput(TypedDict):\\n        city: str\\n\\n    weather: WeatherOutput = (\\n        await ChatOpenAI(model=\"gpt-4o-mini\")\\n        .with_structured_output(WeatherOutput)\\n        .with_config({\"tags\": [\"nostream\"]})\\n        .ainvoke(state[\"messages\"])\\n    )\\n\\n    message = AIMessage(\\n        id=str(uuid.uuid4()),\\n        content=f\"Here\\'s the weather for {weather[\\'city\\']}\",\\n    )\\n\\n    # Emit UI elements associated with the message\\n    push_ui_message(\"weather\", weather, message=message)\\n    return {\"messages\": [message]}\\n\\n\\nworkflow = StateGraph(AgentState)\\nworkflow.add_node(weather)\\nworkflow.add_edge(\"__start__\", \"weather\")\\ngraph = workflow.compile()\\nUse the typedUi utility to emit UI elements from your agent nodes:src/agent/index.tsCopyimport {\\n  typedUi,\\n  uiMessageReducer,\\n} from \"@langchain/langgraph-sdk/react-ui/server\";\\n\\nimport { ChatOpenAI } from \"@langchain/openai\";\\nimport { v4 as uuidv4 } from \"uuid\";\\nimport { z } from \"zod\";\\n\\nimport type ComponentMap from \"./ui.js\";\\n\\nimport {\\n  Annotation,\\n  MessagesAnnotation,\\n  StateGraph,\\n  type LangGraphRunnableConfig,\\n} from \"@langchain/langgraph\";\\n\\nconst AgentState = Annotation.Root({\\n  ...MessagesAnnotation.spec,\\n  ui: Annotation({ reducer: uiMessageReducer, default: () => [] }),\\n});\\n\\nexport const graph = new StateGraph(AgentState)\\n  .addNode(\"weather\", async (state, config) => {\\n    // Provide the type of the component map to ensure\\n    // type safety of `ui.push()` calls as well as\\n    // pushing the messages to the `ui` and sending a custom event as well.\\n    const ui = typedUi<typeof ComponentMap>(config);\\n\\n    const weather = await new ChatOpenAI({ model: \"gpt-4o-mini\" })\\n      .withStructuredOutput(z.object({ city: z.string() }))\\n      .withConfig({ tags: [\"nostream\"] })\\n      .invoke(state.messages);\\n\\n    const response = {\\n      id: uuidv4(),\\n      type: \"ai\",\\n      content: `Here\\'s the weather for ${weather.city}`,\\n    };\\n\\n    // Emit UI elements associated with the AI message\\n    ui.push({ name: \"weather\", props: weather }, { message: response });\\n\\n    return { messages: [response] };\\n  })\\n  .addEdge(\"__start__\", \"weather\")\\n  .compile();\\n\\n\\u200b3. Handle UI elements in your React application\\nOn the client side, you can use useStream() and LoadExternalComponent to display the UI elements.\\nsrc/app/page.tsxCopy\"use client\";\\n\\nimport { useStream } from \"@langchain/langgraph-sdk/react\";\\nimport { LoadExternalComponent } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nexport default function Page() {\\n  const { thread, values } = useStream({\\n    apiUrl: \"http://localhost:2024\",\\n    assistantId: \"agent\",\\n  });\\n\\n  return (\\n    <div>\\n      {thread.messages.map((message) => (\\n        <div key={message.id}>\\n          {message.content}\\n          {values.ui\\n            ?.filter((ui) => ui.metadata?.message_id === message.id)\\n            .map((ui) => (\\n              <LoadExternalComponent key={ui.id} stream={thread} message={ui} />\\n            ))}\\n        </div>\\n      ))}\\n    </div>\\n  );\\n}\\n\\nBehind the scenes, LoadExternalComponent will fetch the JS and CSS for the UI components from LangSmith and render them in a shadow DOM, thus ensuring style isolation from the rest of your application.\\n\\u200bHow-to guides\\n\\u200bProvide custom components on the client side\\nIf you already have the components loaded in your client application, you can provide a map of such components to be rendered directly without fetching the UI code from LangSmith.\\nCopyconst clientComponents = {\\n  weather: WeatherComponent,\\n};\\n\\n<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  components={clientComponents}\\n/>;\\n\\n\\u200bShow loading UI when components are loading\\nYou can provide a fallback UI to be rendered when the components are loading.\\nCopy<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  fallback={<div>Loading...</div>}\\n/>\\n\\n\\u200bCustomise the namespace of UI components.\\nBy default LoadExternalComponent will use the assistantId from useStream() hook to fetch the code for UI components. You can customise this by providing a namespace prop to the LoadExternalComponent component.\\n src/app/page.tsx langgraph.jsonCopy<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  namespace=\"custom-namespace\"\\n/>\\nCopy{\\n  \"ui\": {\\n    \"custom-namespace\": \"./src/agent/ui.tsx\"\\n  }\\n}\\n\\n\\u200bAccess and interact with the thread state from the UI component\\nYou can access the thread state inside the UI component by using the useStreamContext hook.\\nCopyimport { useStreamContext } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nconst WeatherComponent = (props: { city: string }) => {\\n  const { thread, submit } = useStreamContext();\\n  return (\\n    <>\\n      <div>Weather for {props.city}</div>\\n\\n      <button\\n        onClick={() => {\\n          const newMessage = {\\n            type: \"human\",\\n            content: `What\\'s the weather in ${props.city}?`,\\n          };\\n\\n          submit({ messages: [newMessage] });\\n        }}\\n      >\\n        Retry\\n      </button>\\n    </>\\n  );\\n};\\n\\n\\u200bPass additional context to the client components\\nYou can pass additional context to the client components by providing a meta prop to the LoadExternalComponent component.\\nCopy<LoadExternalComponent stream={thread} message={ui} meta={{ userId: \"123\" }} />\\n\\nThen, you can access the meta prop in the UI component by using the useStreamContext hook.\\nCopyimport { useStreamContext } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nconst WeatherComponent = (props: { city: string }) => {\\n  const { meta } = useStreamContext<\\n    { city: string },\\n    { MetaType: { userId?: string } }\\n  >();\\n\\n  return (\\n    <div>\\n      Weather for {props.city} (user: {meta?.userId})\\n    </div>\\n  );\\n};\\n\\n\\u200bStreaming UI messages from the server\\nYou can stream UI messages before the node execution is finished by using the onCustomEvent callback of the useStream() hook. This is especially useful when updating the UI component as the LLM is generating the response.\\nCopyimport { uiMessageReducer } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nconst { thread, submit } = useStream({\\n  apiUrl: \"http://localhost:2024\",\\n  assistantId: \"agent\",\\n  onCustomEvent: (event, options) => {\\n    options.mutate((prev) => {\\n      const ui = uiMessageReducer(prev.ui ?? [], event);\\n      return { ...prev, ui };\\n    });\\n  },\\n});\\n\\nThen you can push updates to the UI component by calling ui.push() / push_ui_message() with the same ID as the UI message you wish to update.\\n Python JS ui.tsxCopyfrom typing import Annotated, Sequence, TypedDict\\n\\nfrom langchain_anthropic import ChatAnthropic\\nfrom langchain.messages import AIMessage, AIMessageChunk, BaseMessage\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.graph.ui import AnyUIMessage, push_ui_message, ui_message_reducer\\n\\n\\nclass AgentState(TypedDict):  # noqa: D101\\n    messages: Annotated[Sequence[BaseMessage], add_messages]\\n    ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]\\n\\n\\nclass CreateTextDocument(TypedDict):\\n    \"\"\"Prepare a document heading for the user.\"\"\"\\n\\n    title: str\\n\\n\\nasync def writer_node(state: AgentState):\\n    model = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\\n    message: AIMessage = await model.bind_tools(\\n        tools=[CreateTextDocument],\\n        tool_choice={\"type\": \"tool\", \"name\": \"CreateTextDocument\"},\\n    ).ainvoke(state[\"messages\"])\\n\\n    tool_call = next(\\n        (x[\"args\"] for x in message.tool_calls if x[\"name\"] == \"CreateTextDocument\"),\\n        None,\\n    )\\n\\n    if tool_call:\\n        ui_message = push_ui_message(\"writer\", tool_call, message=message)\\n        ui_message_id = ui_message[\"id\"]\\n\\n        # We\\'re already streaming the LLM response to the client through UI messages\\n        # so we don\\'t need to stream it again to the `messages` stream mode.\\n        content_stream = model.with_config({\"tags\": [\"nostream\"]}).astream(\\n            f\"Create a document with the title: {tool_call[\\'title\\']}\"\\n        )\\n\\n        content: AIMessageChunk | None = None\\n        async for chunk in content_stream:\\n            content = content + chunk if content else chunk\\n\\n            push_ui_message(\\n                \"writer\",\\n                {\"content\": content.text()},\\n                id=ui_message_id,\\n                message=message,\\n                # Use `merge=rue` to merge props with the existing UI message\\n                merge=True,\\n            )\\n\\n    return {\"messages\": [message]}\\nCopyimport {\\n  Annotation,\\n  MessagesAnnotation,\\n  type LangGraphRunnableConfig,\\n} from \"@langchain/langgraph\";\\nimport { z } from \"zod\";\\nimport { ChatAnthropic } from \"@langchain/anthropic\";\\nimport {\\n  typedUi,\\n  uiMessageReducer,\\n} from \"@langchain/langgraph-sdk/react-ui/server\";\\nimport type { AIMessageChunk } from \"@langchain/core/messages\";\\n\\nimport type ComponentMap from \"./ui\";\\n\\nconst AgentState = Annotation.Root({\\n  ...MessagesAnnotation.spec,\\n  ui: Annotation({ reducer: uiMessageReducer, default: () => [] }),\\n});\\n\\nasync function writerNode(\\n  state: typeof AgentState.State,\\n  config: LangGraphRunnableConfig\\n): Promise<typeof AgentState.Update> {\\n  const ui = typedUi<typeof ComponentMap>(config);\\n\\n  const model = new ChatAnthropic({ model: \"claude-sonnet-4-5-20250929\" });\\n  const message = await model\\n    .bindTools(\\n      [\\n        {\\n          name: \"create_text_document\",\\n          description: \"Prepare a document heading for the user.\",\\n          schema: z.object({ title: z.string() }),\\n        },\\n      ],\\n      { tool_choice: { type: \"tool\", name: \"create_text_document\" } }\\n    )\\n    .invoke(state.messages);\\n\\n  type ToolCall = { name: \"create_text_document\"; args: { title: string } };\\n  const toolCall = message.tool_calls?.find(\\n    (tool): tool is ToolCall => tool.name === \"create_text_document\"\\n  );\\n\\n  if (toolCall) {\\n    const { id, name } = ui.push(\\n      { name: \"writer\", props: { title: toolCall.args.title } },\\n      { message }\\n    );\\n\\n    const contentStream = await model\\n      // We\\'re already streaming the LLM response to the client through UI messages\\n      // so we don\\'t need to stream it again to the `messages` stream mode.\\n      .withConfig({ tags: [\"nostream\"] })\\n      .stream(`Create a short poem with the topic: ${message.text}`);\\n\\n    let content: AIMessageChunk | undefined;\\n    for await (const chunk of contentStream) {\\n      content = content?.concat(chunk) ?? chunk;\\n\\n      ui.push(\\n        { id, name, props: { content: content?.text } },\\n        // Use `merge: true` to merge props with the existing UI message\\n        { message, merge: true }\\n      );\\n    }\\n  }\\n\\n  return { messages: [message] };\\n}\\nCopyfunction WriterComponent(props: { title: string; content?: string }) {\\n  return (\\n    <article>\\n      <h2>{props.title}</h2>\\n      <p style={{ whiteSpace: \"pre-wrap\" }}>{props.content}</p>\\n    </article>\\n  );\\n}\\n\\nexport default {\\n  weather: WriterComponent,\\n};\\n\\n\\u200bRemove UI messages from state\\nSimilar to how messages can be removed from the state by appending a RemoveMessage you can remove an UI message from the state by calling remove_ui_message / ui.delete with the ID of the UI message.\\n Python JSCopyfrom langgraph.graph.ui import push_ui_message, delete_ui_message\\n\\n# push message\\nmessage = push_ui_message(\"weather\", {\"city\": \"London\"})\\n\\n# remove said message\\ndelete_ui_message(message[\"id\"])\\nCopy// push message\\nconst message = ui.push({ name: \"weather\", props: { city: \"London\" } });\\n\\n// remove said message\\nui.delete(message.id);\\n\\n\\u200bLearn more\\n\\nJS/TS SDK Reference\\n\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoDeploy other frameworksPreviousLangSmith StudioNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by\\n')]\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c4cc17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 , create chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eaae10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='How to implement generative user interfaces with LangGraph - Docs by LangChainSkip to main contentDocs by LangChain home pageLangSmithSearch...⌘KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationTutorialsHow to implement generative user interfaces with LangGraphGet startedObservabilityEvaluationPrompt engineeringDeploymentPlatform setupReferenceOverviewTest locallyApp developmentCloud quickstartLocal development & testingConfigure app for deploymentApplication structureSetupDeployment componentsRebuild graph at runtimeInteract with a deployment using RemoteGraphAdd semantic search to your agent deploymentAdd TTLs to your applicationConfigure Agent Server for scaleImplement a CI/CD pipelineDeployment guidesCloudWith control planeStandalone serversTroubleshootingApp developmentData modelsCore capabilitiesTutorialsDeploy other frameworks (e.g., Strands, CrewAI)Implement generative user interfaces with LangGraphStudioOverviewQuickstartRuns, assistants, threadsTraces, datasets,'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='pipelineDeployment guidesCloudWith control planeStandalone serversTroubleshootingApp developmentData modelsCore capabilitiesTutorialsDeploy other frameworks (e.g., Strands, CrewAI)Implement generative user interfaces with LangGraphStudioOverviewQuickstartRuns, assistants, threadsTraces, datasets, promptsTroubleshootingAuth & access controlOverviewAdd custom authenticationSet up custom authenticationMake conversations privateConnect an authentication providerDocument API authentication in OpenAPISet up Agent Auth (Beta)Server customizationAdd custom lifespan eventsAdd custom middlewareAdd custom routesEncryption at-restConfigurable headersLogging HeadersOn this pageTutorial1. Define and configure UI components2. Send the UI components in your graph3. Handle UI elements in your React applicationHow-to guidesProvide custom components on the client sideShow loading UI when components are loadingCustomise the namespace of UI components.Access and interact with the thread state from the UI'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='UI components2. Send the UI components in your graph3. Handle UI elements in your React applicationHow-to guidesProvide custom components on the client sideShow loading UI when components are loadingCustomise the namespace of UI components.Access and interact with the thread state from the UI componentPass additional context to the client componentsStreaming UI messages from the serverRemove UI messages from stateLearn moreApp developmentTutorialsHow to implement generative user interfaces with LangGraphCopy pageCopy pagePrerequisites'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='LangSmith\\nAgent Server\\nuseStream() React Hook'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='Generative user interfaces (Generative UI) allows agents to go beyond text and generate rich user interfaces. This enables creating more interactive and context-aware applications where the UI adapts based on the conversation flow and AI responses.\\n\\nLangSmith supports colocating your React components with your graph code. This allows you to focus on building specific UI components for your graph while easily plugging into existing chat interfaces such as Agent Chat and loading the code only when actually needed.\\n\\u200bTutorial\\n\\u200b1. Define and configure UI components\\nFirst, create your first UI component. For each component you need to provide an unique identifier that will be used to reference the component in your graph code.\\nsrc/agent/ui.tsxCopyconst WeatherComponent = (props: { city: string }) => {\\n  return <div>Weather for {props.city}</div>;\\n};\\n\\nexport default {\\n  weather: WeatherComponent,\\n};'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='export default {\\n  weather: WeatherComponent,\\n};\\n\\nNext, define your UI components in your langgraph.json configuration:\\nCopy{\\n  \"node_version\": \"20\",\\n  \"graphs\": {\\n    \"agent\": \"./src/agent/index.ts:graph\"\\n  },\\n  \"ui\": {\\n    \"agent\": \"./src/agent/ui.tsx\"\\n  }\\n}\\n\\nThe ui section points to the UI components that will be used by graphs. By default, we recommend using the same key as the graph name, but you can split out the components however you like, see Customise the namespace of UI components for more details.\\nLangSmith will automatically bundle your UI components code and styles and serve them as external assets that can be loaded by the LoadExternalComponent component. Some dependencies such as react and react-dom will be automatically excluded from the bundle.\\nCSS and Tailwind 4.x is also supported out of the box, so you can freely use Tailwind classes as well as shadcn/ui in your UI components.\\n src/agent/ui.tsx src/agent/styles.cssCopyimport \"./styles.css\";'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='const WeatherComponent = (props: { city: string }) => {\\n  return <div className=\"bg-red-500\">Weather for {props.city}</div>;\\n};\\n\\nexport default {\\n  weather: WeatherComponent,\\n};\\nCopy@import \"tailwindcss\";\\n\\n\\u200b2. Send the UI components in your graph\\n Python JSsrc/agent.pyCopyimport uuid\\nfrom typing import Annotated, Sequence, TypedDict\\n\\nfrom langchain.messages import AIMessage\\nfrom langchain_core.messages import BaseMessage\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.graph.ui import AnyUIMessage, ui_message_reducer, push_ui_message\\n\\n\\nclass AgentState(TypedDict):  # noqa: D101\\n    messages: Annotated[Sequence[BaseMessage], add_messages]\\n    ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]\\n\\n\\nasync def weather(state: AgentState):\\n    class WeatherOutput(TypedDict):\\n        city: str'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='class AgentState(TypedDict):  # noqa: D101\\n    messages: Annotated[Sequence[BaseMessage], add_messages]\\n    ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]\\n\\n\\nasync def weather(state: AgentState):\\n    class WeatherOutput(TypedDict):\\n        city: str\\n\\n    weather: WeatherOutput = (\\n        await ChatOpenAI(model=\"gpt-4o-mini\")\\n        .with_structured_output(WeatherOutput)\\n        .with_config({\"tags\": [\"nostream\"]})\\n        .ainvoke(state[\"messages\"])\\n    )\\n\\n    message = AIMessage(\\n        id=str(uuid.uuid4()),\\n        content=f\"Here\\'s the weather for {weather[\\'city\\']}\",\\n    )\\n\\n    # Emit UI elements associated with the message\\n    push_ui_message(\"weather\", weather, message=message)\\n    return {\"messages\": [message]}'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='message = AIMessage(\\n        id=str(uuid.uuid4()),\\n        content=f\"Here\\'s the weather for {weather[\\'city\\']}\",\\n    )\\n\\n    # Emit UI elements associated with the message\\n    push_ui_message(\"weather\", weather, message=message)\\n    return {\"messages\": [message]}\\n\\n\\nworkflow = StateGraph(AgentState)\\nworkflow.add_node(weather)\\nworkflow.add_edge(\"__start__\", \"weather\")\\ngraph = workflow.compile()\\nUse the typedUi utility to emit UI elements from your agent nodes:src/agent/index.tsCopyimport {\\n  typedUi,\\n  uiMessageReducer,\\n} from \"@langchain/langgraph-sdk/react-ui/server\";\\n\\nimport { ChatOpenAI } from \"@langchain/openai\";\\nimport { v4 as uuidv4 } from \"uuid\";\\nimport { z } from \"zod\";\\n\\nimport type ComponentMap from \"./ui.js\";\\n\\nimport {\\n  Annotation,\\n  MessagesAnnotation,\\n  StateGraph,\\n  type LangGraphRunnableConfig,\\n} from \"@langchain/langgraph\";\\n\\nconst AgentState = Annotation.Root({\\n  ...MessagesAnnotation.spec,\\n  ui: Annotation({ reducer: uiMessageReducer, default: () => [] }),\\n});'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='import {\\n  Annotation,\\n  MessagesAnnotation,\\n  StateGraph,\\n  type LangGraphRunnableConfig,\\n} from \"@langchain/langgraph\";\\n\\nconst AgentState = Annotation.Root({\\n  ...MessagesAnnotation.spec,\\n  ui: Annotation({ reducer: uiMessageReducer, default: () => [] }),\\n});\\n\\nexport const graph = new StateGraph(AgentState)\\n  .addNode(\"weather\", async (state, config) => {\\n    // Provide the type of the component map to ensure\\n    // type safety of `ui.push()` calls as well as\\n    // pushing the messages to the `ui` and sending a custom event as well.\\n    const ui = typedUi<typeof ComponentMap>(config);\\n\\n    const weather = await new ChatOpenAI({ model: \"gpt-4o-mini\" })\\n      .withStructuredOutput(z.object({ city: z.string() }))\\n      .withConfig({ tags: [\"nostream\"] })\\n      .invoke(state.messages);\\n\\n    const response = {\\n      id: uuidv4(),\\n      type: \"ai\",\\n      content: `Here\\'s the weather for ${weather.city}`,\\n    };'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='const response = {\\n      id: uuidv4(),\\n      type: \"ai\",\\n      content: `Here\\'s the weather for ${weather.city}`,\\n    };\\n\\n    // Emit UI elements associated with the AI message\\n    ui.push({ name: \"weather\", props: weather }, { message: response });\\n\\n    return { messages: [response] };\\n  })\\n  .addEdge(\"__start__\", \"weather\")\\n  .compile();\\n\\n\\u200b3. Handle UI elements in your React application\\nOn the client side, you can use useStream() and LoadExternalComponent to display the UI elements.\\nsrc/app/page.tsxCopy\"use client\";\\n\\nimport { useStream } from \"@langchain/langgraph-sdk/react\";\\nimport { LoadExternalComponent } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nexport default function Page() {\\n  const { thread, values } = useStream({\\n    apiUrl: \"http://localhost:2024\",\\n    assistantId: \"agent\",\\n  });'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='import { useStream } from \"@langchain/langgraph-sdk/react\";\\nimport { LoadExternalComponent } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nexport default function Page() {\\n  const { thread, values } = useStream({\\n    apiUrl: \"http://localhost:2024\",\\n    assistantId: \"agent\",\\n  });\\n\\n  return (\\n    <div>\\n      {thread.messages.map((message) => (\\n        <div key={message.id}>\\n          {message.content}\\n          {values.ui\\n            ?.filter((ui) => ui.metadata?.message_id === message.id)\\n            .map((ui) => (\\n              <LoadExternalComponent key={ui.id} stream={thread} message={ui} />\\n            ))}\\n        </div>\\n      ))}\\n    </div>\\n  );\\n}'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='Behind the scenes, LoadExternalComponent will fetch the JS and CSS for the UI components from LangSmith and render them in a shadow DOM, thus ensuring style isolation from the rest of your application.\\n\\u200bHow-to guides\\n\\u200bProvide custom components on the client side\\nIf you already have the components loaded in your client application, you can provide a map of such components to be rendered directly without fetching the UI code from LangSmith.\\nCopyconst clientComponents = {\\n  weather: WeatherComponent,\\n};\\n\\n<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  components={clientComponents}\\n/>;\\n\\n\\u200bShow loading UI when components are loading\\nYou can provide a fallback UI to be rendered when the components are loading.\\nCopy<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  fallback={<div>Loading...</div>}\\n/>'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='\\u200bShow loading UI when components are loading\\nYou can provide a fallback UI to be rendered when the components are loading.\\nCopy<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  fallback={<div>Loading...</div>}\\n/>\\n\\n\\u200bCustomise the namespace of UI components.\\nBy default LoadExternalComponent will use the assistantId from useStream() hook to fetch the code for UI components. You can customise this by providing a namespace prop to the LoadExternalComponent component.\\n src/app/page.tsx langgraph.jsonCopy<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  namespace=\"custom-namespace\"\\n/>\\nCopy{\\n  \"ui\": {\\n    \"custom-namespace\": \"./src/agent/ui.tsx\"\\n  }\\n}\\n\\n\\u200bAccess and interact with the thread state from the UI component\\nYou can access the thread state inside the UI component by using the useStreamContext hook.\\nCopyimport { useStreamContext } from \"@langchain/langgraph-sdk/react-ui\";'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='\\u200bAccess and interact with the thread state from the UI component\\nYou can access the thread state inside the UI component by using the useStreamContext hook.\\nCopyimport { useStreamContext } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nconst WeatherComponent = (props: { city: string }) => {\\n  const { thread, submit } = useStreamContext();\\n  return (\\n    <>\\n      <div>Weather for {props.city}</div>\\n\\n      <button\\n        onClick={() => {\\n          const newMessage = {\\n            type: \"human\",\\n            content: `What\\'s the weather in ${props.city}?`,\\n          };\\n\\n          submit({ messages: [newMessage] });\\n        }}\\n      >\\n        Retry\\n      </button>\\n    </>\\n  );\\n};\\n\\n\\u200bPass additional context to the client components\\nYou can pass additional context to the client components by providing a meta prop to the LoadExternalComponent component.\\nCopy<LoadExternalComponent stream={thread} message={ui} meta={{ userId: \"123\" }} />'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='\\u200bPass additional context to the client components\\nYou can pass additional context to the client components by providing a meta prop to the LoadExternalComponent component.\\nCopy<LoadExternalComponent stream={thread} message={ui} meta={{ userId: \"123\" }} />\\n\\nThen, you can access the meta prop in the UI component by using the useStreamContext hook.\\nCopyimport { useStreamContext } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nconst WeatherComponent = (props: { city: string }) => {\\n  const { meta } = useStreamContext<\\n    { city: string },\\n    { MetaType: { userId?: string } }\\n  >();\\n\\n  return (\\n    <div>\\n      Weather for {props.city} (user: {meta?.userId})\\n    </div>\\n  );\\n};'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='const WeatherComponent = (props: { city: string }) => {\\n  const { meta } = useStreamContext<\\n    { city: string },\\n    { MetaType: { userId?: string } }\\n  >();\\n\\n  return (\\n    <div>\\n      Weather for {props.city} (user: {meta?.userId})\\n    </div>\\n  );\\n};\\n\\n\\u200bStreaming UI messages from the server\\nYou can stream UI messages before the node execution is finished by using the onCustomEvent callback of the useStream() hook. This is especially useful when updating the UI component as the LLM is generating the response.\\nCopyimport { uiMessageReducer } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nconst { thread, submit } = useStream({\\n  apiUrl: \"http://localhost:2024\",\\n  assistantId: \"agent\",\\n  onCustomEvent: (event, options) => {\\n    options.mutate((prev) => {\\n      const ui = uiMessageReducer(prev.ui ?? [], event);\\n      return { ...prev, ui };\\n    });\\n  },\\n});'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='const { thread, submit } = useStream({\\n  apiUrl: \"http://localhost:2024\",\\n  assistantId: \"agent\",\\n  onCustomEvent: (event, options) => {\\n    options.mutate((prev) => {\\n      const ui = uiMessageReducer(prev.ui ?? [], event);\\n      return { ...prev, ui };\\n    });\\n  },\\n});\\n\\nThen you can push updates to the UI component by calling ui.push() / push_ui_message() with the same ID as the UI message you wish to update.\\n Python JS ui.tsxCopyfrom typing import Annotated, Sequence, TypedDict\\n\\nfrom langchain_anthropic import ChatAnthropic\\nfrom langchain.messages import AIMessage, AIMessageChunk, BaseMessage\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.graph.ui import AnyUIMessage, push_ui_message, ui_message_reducer\\n\\n\\nclass AgentState(TypedDict):  # noqa: D101\\n    messages: Annotated[Sequence[BaseMessage], add_messages]\\n    ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='class AgentState(TypedDict):  # noqa: D101\\n    messages: Annotated[Sequence[BaseMessage], add_messages]\\n    ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]\\n\\n\\nclass CreateTextDocument(TypedDict):\\n    \"\"\"Prepare a document heading for the user.\"\"\"\\n\\n    title: str\\n\\n\\nasync def writer_node(state: AgentState):\\n    model = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\\n    message: AIMessage = await model.bind_tools(\\n        tools=[CreateTextDocument],\\n        tool_choice={\"type\": \"tool\", \"name\": \"CreateTextDocument\"},\\n    ).ainvoke(state[\"messages\"])\\n\\n    tool_call = next(\\n        (x[\"args\"] for x in message.tool_calls if x[\"name\"] == \"CreateTextDocument\"),\\n        None,\\n    )\\n\\n    if tool_call:\\n        ui_message = push_ui_message(\"writer\", tool_call, message=message)\\n        ui_message_id = ui_message[\"id\"]'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='tool_call = next(\\n        (x[\"args\"] for x in message.tool_calls if x[\"name\"] == \"CreateTextDocument\"),\\n        None,\\n    )\\n\\n    if tool_call:\\n        ui_message = push_ui_message(\"writer\", tool_call, message=message)\\n        ui_message_id = ui_message[\"id\"]\\n\\n        # We\\'re already streaming the LLM response to the client through UI messages\\n        # so we don\\'t need to stream it again to the `messages` stream mode.\\n        content_stream = model.with_config({\"tags\": [\"nostream\"]}).astream(\\n            f\"Create a document with the title: {tool_call[\\'title\\']}\"\\n        )\\n\\n        content: AIMessageChunk | None = None\\n        async for chunk in content_stream:\\n            content = content + chunk if content else chunk'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='content: AIMessageChunk | None = None\\n        async for chunk in content_stream:\\n            content = content + chunk if content else chunk\\n\\n            push_ui_message(\\n                \"writer\",\\n                {\"content\": content.text()},\\n                id=ui_message_id,\\n                message=message,\\n                # Use `merge=rue` to merge props with the existing UI message\\n                merge=True,\\n            )\\n\\n    return {\"messages\": [message]}\\nCopyimport {\\n  Annotation,\\n  MessagesAnnotation,\\n  type LangGraphRunnableConfig,\\n} from \"@langchain/langgraph\";\\nimport { z } from \"zod\";\\nimport { ChatAnthropic } from \"@langchain/anthropic\";\\nimport {\\n  typedUi,\\n  uiMessageReducer,\\n} from \"@langchain/langgraph-sdk/react-ui/server\";\\nimport type { AIMessageChunk } from \"@langchain/core/messages\";\\n\\nimport type ComponentMap from \"./ui\";\\n\\nconst AgentState = Annotation.Root({\\n  ...MessagesAnnotation.spec,\\n  ui: Annotation({ reducer: uiMessageReducer, default: () => [] }),\\n});'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='import type ComponentMap from \"./ui\";\\n\\nconst AgentState = Annotation.Root({\\n  ...MessagesAnnotation.spec,\\n  ui: Annotation({ reducer: uiMessageReducer, default: () => [] }),\\n});\\n\\nasync function writerNode(\\n  state: typeof AgentState.State,\\n  config: LangGraphRunnableConfig\\n): Promise<typeof AgentState.Update> {\\n  const ui = typedUi<typeof ComponentMap>(config);\\n\\n  const model = new ChatAnthropic({ model: \"claude-sonnet-4-5-20250929\" });\\n  const message = await model\\n    .bindTools(\\n      [\\n        {\\n          name: \"create_text_document\",\\n          description: \"Prepare a document heading for the user.\",\\n          schema: z.object({ title: z.string() }),\\n        },\\n      ],\\n      { tool_choice: { type: \"tool\", name: \"create_text_document\" } }\\n    )\\n    .invoke(state.messages);\\n\\n  type ToolCall = { name: \"create_text_document\"; args: { title: string } };\\n  const toolCall = message.tool_calls?.find(\\n    (tool): tool is ToolCall => tool.name === \"create_text_document\"\\n  );'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='type ToolCall = { name: \"create_text_document\"; args: { title: string } };\\n  const toolCall = message.tool_calls?.find(\\n    (tool): tool is ToolCall => tool.name === \"create_text_document\"\\n  );\\n\\n  if (toolCall) {\\n    const { id, name } = ui.push(\\n      { name: \"writer\", props: { title: toolCall.args.title } },\\n      { message }\\n    );\\n\\n    const contentStream = await model\\n      // We\\'re already streaming the LLM response to the client through UI messages\\n      // so we don\\'t need to stream it again to the `messages` stream mode.\\n      .withConfig({ tags: [\"nostream\"] })\\n      .stream(`Create a short poem with the topic: ${message.text}`);\\n\\n    let content: AIMessageChunk | undefined;\\n    for await (const chunk of contentStream) {\\n      content = content?.concat(chunk) ?? chunk;\\n\\n      ui.push(\\n        { id, name, props: { content: content?.text } },\\n        // Use `merge: true` to merge props with the existing UI message\\n        { message, merge: true }\\n      );\\n    }\\n  }'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='ui.push(\\n        { id, name, props: { content: content?.text } },\\n        // Use `merge: true` to merge props with the existing UI message\\n        { message, merge: true }\\n      );\\n    }\\n  }\\n\\n  return { messages: [message] };\\n}\\nCopyfunction WriterComponent(props: { title: string; content?: string }) {\\n  return (\\n    <article>\\n      <h2>{props.title}</h2>\\n      <p style={{ whiteSpace: \"pre-wrap\" }}>{props.content}</p>\\n    </article>\\n  );\\n}\\n\\nexport default {\\n  weather: WriterComponent,\\n};\\n\\n\\u200bRemove UI messages from state\\nSimilar to how messages can be removed from the state by appending a RemoveMessage you can remove an UI message from the state by calling remove_ui_message / ui.delete with the ID of the UI message.\\n Python JSCopyfrom langgraph.graph.ui import push_ui_message, delete_ui_message\\n\\n# push message\\nmessage = push_ui_message(\"weather\", {\"city\": \"London\"})'),\n",
       " Document(metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='# push message\\nmessage = push_ui_message(\"weather\", {\"city\": \"London\"})\\n\\n# remove said message\\ndelete_ui_message(message[\"id\"])\\nCopy// push message\\nconst message = ui.push({ name: \"weather\", props: { city: \"London\" } });\\n\\n// remove said message\\nui.delete(message.id);\\n\\n\\u200bLearn more\\n\\nJS/TS SDK Reference\\n\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoDeploy other frameworksPreviousLangSmith StudioNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, chunk_overlap = 300\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)\n",
    "chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0181bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3: create an embedder\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddder = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5596e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4: get a vector db, embeded vec store in db at same time for time optimization\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(chunks,embeddder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32590b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Behind the scenes, LoadExternalComponent will fetch the JS and CSS for the UI components from LangSmith and render them in a shadow DOM, thus ensuring style isolation from the rest of your application.\\n\\u200bHow-to guides\\n\\u200bProvide custom components on the client side\\nIf you already have the components loaded in your client application, you can provide a map of such components to be rendered directly without fetching the UI code from LangSmith.\\nCopyconst clientComponents = {\\n  weather: WeatherComponent,\\n};\\n\\n<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  components={clientComponents}\\n/>;\\n\\n\\u200bShow loading UI when components are loading\\nYou can provide a fallback UI to be rendered when the components are loading.\\nCopy<LoadExternalComponent\\n  stream={thread}\\n  message={ui}\\n  fallback={<div>Loading...</div>}\\n/>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What will LoadExternalComponent use by default\"\n",
    "res = db.similarity_search(query)\n",
    "res[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a100ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the question using only the context below:\\n    <context>\\n    {context}\\n    </context>\\n    \\n    '), additional_kwargs={})])\n",
       "| ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x000001DA76444520>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001DA76447C40>, root_client=<openai.OpenAI object at 0x000001DA764455A0>, root_async_client=<openai.AsyncOpenAI object at 0x000001DA76447A00>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Document Chain(new concept)\n",
    "\n",
    "#install langchain_classic\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the question using only the context below:\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o\")\n",
    "doc_chain = create_stuff_documents_chain(llm,prompt)\n",
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acba375e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the context provided seems incomplete. Could you please provide more information or clarify your question?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "doc_chain.invoke(\n",
    "    {\n",
    "        \"input\":\"RemoveMessage you can remove an UI message from the state by calling\",\n",
    "        \"context\":[Document(page_content = \"RemoveMessage you can remove an UI message from the state by calling\")]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "575f776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_retrieval_chain\n",
    "retriever = db.as_retriever() # db - faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b022f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever,doc_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc7761f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001DA73A938E0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    Answer the question using only the context below:\\n    <context>\\n    {context}\\n    </context>\\n    \\n    '), additional_kwargs={})])\n",
       "            | ChatOpenAI(profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True}, client=<openai.resources.chat.completions.completions.Completions object at 0x000001DA76444520>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001DA76447C40>, root_client=<openai.OpenAI object at 0x000001DA764455A0>, root_async_client=<openai.AsyncOpenAI object at 0x000001DA76447A00>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain\n",
    "# type(retrieval_chain) #a runable is a object which takes  input -> does work -> return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d03e8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'emoveMessage you can remove an UI message from the state by calling',\n",
       " 'context': [Document(id='df151a6f-f99d-4946-9400-d41efde27343', metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='# push message\\nmessage = push_ui_message(\"weather\", {\"city\": \"London\"})\\n\\n# remove said message\\ndelete_ui_message(message[\"id\"])\\nCopy// push message\\nconst message = ui.push({ name: \"weather\", props: { city: \"London\" } });\\n\\n// remove said message\\nui.delete(message.id);\\n\\n\\u200bLearn more\\n\\nJS/TS SDK Reference\\n\\n\\nEdit this page on GitHub or file an issue.\\nConnect these docs to Claude, VSCode, and more via MCP for real-time answers.Was this page helpful?YesNoDeploy other frameworksPreviousLangSmith StudioNext⌘IDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by'),\n",
       "  Document(id='c4e5a82a-1442-4ee9-a950-c752c8f9880d', metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='ui.push(\\n        { id, name, props: { content: content?.text } },\\n        // Use `merge: true` to merge props with the existing UI message\\n        { message, merge: true }\\n      );\\n    }\\n  }\\n\\n  return { messages: [message] };\\n}\\nCopyfunction WriterComponent(props: { title: string; content?: string }) {\\n  return (\\n    <article>\\n      <h2>{props.title}</h2>\\n      <p style={{ whiteSpace: \"pre-wrap\" }}>{props.content}</p>\\n    </article>\\n  );\\n}\\n\\nexport default {\\n  weather: WriterComponent,\\n};\\n\\n\\u200bRemove UI messages from state\\nSimilar to how messages can be removed from the state by appending a RemoveMessage you can remove an UI message from the state by calling remove_ui_message / ui.delete with the ID of the UI message.\\n Python JSCopyfrom langgraph.graph.ui import push_ui_message, delete_ui_message\\n\\n# push message\\nmessage = push_ui_message(\"weather\", {\"city\": \"London\"})'),\n",
       "  Document(id='c220388e-172e-4b9b-a7cb-0bbd49904fd0', metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='const { thread, submit } = useStream({\\n  apiUrl: \"http://localhost:2024\",\\n  assistantId: \"agent\",\\n  onCustomEvent: (event, options) => {\\n    options.mutate((prev) => {\\n      const ui = uiMessageReducer(prev.ui ?? [], event);\\n      return { ...prev, ui };\\n    });\\n  },\\n});\\n\\nThen you can push updates to the UI component by calling ui.push() / push_ui_message() with the same ID as the UI message you wish to update.\\n Python JS ui.tsxCopyfrom typing import Annotated, Sequence, TypedDict\\n\\nfrom langchain_anthropic import ChatAnthropic\\nfrom langchain.messages import AIMessage, AIMessageChunk, BaseMessage\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nfrom langgraph.graph.ui import AnyUIMessage, push_ui_message, ui_message_reducer\\n\\n\\nclass AgentState(TypedDict):  # noqa: D101\\n    messages: Annotated[Sequence[BaseMessage], add_messages]\\n    ui: Annotated[Sequence[AnyUIMessage], ui_message_reducer]'),\n",
       "  Document(id='1884fe38-a864-46dc-824a-24b1d7353622', metadata={'source': 'https://docs.langchain.com/langsmith/generative-ui-react', 'title': 'How to implement generative user interfaces with LangGraph - Docs by LangChain', 'language': 'en'}, page_content='const WeatherComponent = (props: { city: string }) => {\\n  const { meta } = useStreamContext<\\n    { city: string },\\n    { MetaType: { userId?: string } }\\n  >();\\n\\n  return (\\n    <div>\\n      Weather for {props.city} (user: {meta?.userId})\\n    </div>\\n  );\\n};\\n\\n\\u200bStreaming UI messages from the server\\nYou can stream UI messages before the node execution is finished by using the onCustomEvent callback of the useStream() hook. This is especially useful when updating the UI component as the LLM is generating the response.\\nCopyimport { uiMessageReducer } from \"@langchain/langgraph-sdk/react-ui\";\\n\\nconst { thread, submit } = useStream({\\n  apiUrl: \"http://localhost:2024\",\\n  assistantId: \"agent\",\\n  onCustomEvent: (event, options) => {\\n    options.mutate((prev) => {\\n      const ui = uiMessageReducer(prev.ui ?? [], event);\\n      return { ...prev, ui };\\n    });\\n  },\\n});')],\n",
       " 'answer': 'How can you update a UI component message that has already been pushed?\\n\\nYou can update a UI component message that has already been pushed by calling `ui.push()` or `push_ui_message()` with the same ID as the UI message you wish to update.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the response from the llm\n",
    "\n",
    "response = retrieval_chain.invoke({\n",
    "    \"input\": \"emoveMessage you can remove an UI message from the state by calling\"\n",
    "})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b3d75e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can you update a UI component message that has already been pushed?\\n\\nYou can update a UI component message that has already been pushed by calling `ui.push()` or `push_ui_message()` with the same ID as the UI message you wish to update.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
